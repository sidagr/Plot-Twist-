{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f572e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "328cc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2734aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "#Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "#Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    # Update message history with response:\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "#Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "#Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97ea4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"test_17\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "412096db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanAttributes:\n",
    "    def __init__(self):\n",
    "        # Initialize the 'map' attribute as a dictionary where all attributes are keys with empty strings as default values\n",
    "        self.map = {\n",
    "            \"Name\": \"\",\n",
    "            \"Age\": \"\",\n",
    "            \"Gender\": \"\",\n",
    "            \"Nationality\": \"\",\n",
    "            \"Profession\": \"\",\n",
    "            \"Education\": \"\",\n",
    "            \"Languages Spoken\": \"\",\n",
    "            \"Hobbies\": \"\",\n",
    "            \"Personality Traits\": \"\",\n",
    "            \"Values\": \"\",\n",
    "            \"Beliefs\": \"\",\n",
    "            \"Favorite Books\": \"\",\n",
    "            \"Favorite Movies\": \"\",\n",
    "            \"Life Goals\": \"\",\n",
    "            \"Dreams\": \"\",\n",
    "            \"Bucket List\": \"\",\n",
    "            \"Relationships\": \"\",\n",
    "            \"Current Emotional State\": \"\",\n",
    "        }\n",
    "\n",
    "    def set_attribute(self, key, value):\n",
    "        \"\"\"Set an attribute dynamically in the map.\"\"\"\n",
    "        if key in self.map:\n",
    "            self.map[key] = str(value)  # Convert value to string before storing\n",
    "        else:\n",
    "            print(f\"❗ Attribute '{key}' not found.\")\n",
    "\n",
    "    def get_attribute(self, key):\n",
    "        \"\"\"Get the value of a specific attribute from the map.\"\"\"\n",
    "        return self.map.get(key, \"Unknown\")\n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"Return a full summary of the attributes from the map.\"\"\"\n",
    "        for key, value in self.map.items():\n",
    "            if value:  # If the value is an empty string\n",
    "                print(\"the attribute is: \", key, \"and the value is: \", value)\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Return a pretty-printed string summary of the attributes in the map.\"\"\"\n",
    "        return \"\\n\".join([f\"{key}: {value or 'Unknown'}\" for key, value in self.map.items()])\n",
    "\n",
    "    def missing_attributes(self):\n",
    "        missing = []\n",
    "        for key, value in self.map.items():\n",
    "            if not value:  # If the value is an empty string\n",
    "                missing.append(key)\n",
    "\n",
    "        if not missing:\n",
    "            return \"✅ All attributes have been filled out.\"\n",
    "        else:\n",
    "            return f\"❗ The following attributes are still missing: {', '.join(missing)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b0c97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=' \\n\\n    My HumanAttributes class has the following attributes \"Name\", \"Age\", Gender\", \"Nationality\", \"Profession\", \"Education\", \"Languages Spoken\", \"Hobbies\"\\n            ,\"Personality Traits\", \"Values\", \"Beliefs\", \"Favorite Books\", \"Favorite Movies\", \"Life Goals\", \"Dreams\", \"Bucket List\", \"Relationships\", \"Current Emotional State\"\\n\\n   You are a friendly and inquisitive AI chat bot. I want you to remember all the attributes for this class and fill it up as you find it. Ask questions to get answers about the human and\\n   when you do, find out other attributes in the next question. Remember to keep your reply to a maximum of six lines whilst having only one question at a time. Also, don\\'t be robotic.\\n\\n   **Rules**:\\n    1. Be conversational and friendly.\\n    2. Ask only one question at a time if asking a question.\\n    3. Only ask for missing information.\\n    4. Never repeat questions.\\n    5. Adapt based on their responses.\\n    6. Limit questions and conversation to a maximum of three lines.\\n    7. Don\\'t deviate to much from your question and answers.\\n\\n    Make sure to address the human properly.\\n', additional_kwargs={}, response_metadata={}, id='8db55efb-8ecb-4506-a58e-cfc98f808e3b'),\n",
       "  AIMessage(content=\"Alright, sounds fun! Let's get to know you better.\\n\\nFirst off, what's your name? I'm eager to put a name to the face, so to speak!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run-8ee68e95-dc91-4f07-864a-1605fc8dcd78-0', usage_metadata={'input_tokens': 259, 'output_tokens': 41, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\" \n",
    "\n",
    "    My HumanAttributes class has the following attributes \"Name\", \"Age\", Gender\", \"Nationality\", \"Profession\", \"Education\", \"Languages Spoken\", \"Hobbies\"\n",
    "            ,\"Personality Traits\", \"Values\", \"Beliefs\", \"Favorite Books\", \"Favorite Movies\", \"Life Goals\", \"Dreams\", \"Bucket List\", \"Relationships\", \"Current Emotional State\"\n",
    "\n",
    "   You are a friendly and inquisitive AI chat bot. I want you to remember all the attributes for this class and fill it up as you find it. Ask questions to get answers about the human and\n",
    "   when you do, find out other attributes in the next question. Remember to keep your reply to a maximum of six lines whilst having only one question at a time. Also, don't be robotic.\n",
    "\n",
    "   **Rules**:\n",
    "    1. Be conversational and friendly.\n",
    "    2. Ask only one question at a time if asking a question.\n",
    "    3. Only ask for missing information.\n",
    "    4. Never repeat questions.\n",
    "    5. Adapt based on their responses.\n",
    "    6. Limit questions and conversation to a maximum of three lines.\n",
    "    7. Don't deviate to much from your question and answers.\n",
    "\n",
    "    Make sure to address the human properly.\n",
    "\"\"\"\n",
    "\n",
    "app.invoke({\"messages\": [HumanMessage(content=system_prompt)]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d73512cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter question generator server running on port 5001...\n",
      " * Serving Flask app '__main__'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5001\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from flask import Flask, request, jsonify\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "jupyter_app = Flask(__name__)\n",
    "\n",
    "human = HumanAttributes()\n",
    "\n",
    "@jupyter_app.route('/trigger-feedback', methods=['POST'])\n",
    "def trigger_feedback():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        if not data or 'answer' not in data:\n",
    "            return jsonify({'error': 'Missing answer in request'}), 400\n",
    "        \n",
    "        user_message = data['answer']\n",
    "\n",
    "        missing_attributes = \"The user is about to send a message. Converse  and be friendly with them, keeping in mind the missing attributes. Find out only one attribute from a statement, without making it so blatant. Be conversational and do not sound robotic.\" + human.missing_attributes()\n",
    "        \n",
    "        # Let the LLM know there is an incoming user message.\n",
    "        \n",
    "        final_message = missing_attributes + \"The sentence after this is the user message enter an appropriate message to the user based on my prompting.\" + user_message\n",
    "        print(final_message)\n",
    "        # Process message through LangGraph\n",
    "        response_to_user = app.invoke(\n",
    "            {\"messages\": [HumanMessage(content=final_message)]},\n",
    "            config=config\n",
    "        )\n",
    "\n",
    "        attribute = app.invoke(\n",
    "            {\"messages\": [HumanMessage(content=\"Based on the user message, and the HumanAttributes class write a single string of the attribute. For eg like Name and Age. Do not include quotations, punctuations or space.\")]},\n",
    "            config=config\n",
    "        )\n",
    "\n",
    "        value_message = \"So what is the user's \" + attribute[\"messages\"][-1].content\n",
    "\n",
    "        value = app.invoke(\n",
    "            {\"messages\": [HumanMessage(content=value_message)]},\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        human.set_attribute(attribute[\"messages\"][-1].content, value[\"messages\"][-1].content)\n",
    "\n",
    "        print(attribute[\"messages\"][-1].content, \" \", value[\"messages\"][-1].content)\n",
    "\n",
    "        # Extract the last message content\n",
    "        feedback = response_to_user[\"messages\"][-1].content\n",
    "        \n",
    "        return jsonify({\n",
    "            'feedback': feedback,\n",
    "            'status': 'success'\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating feedback: {str(e)}\", flush=True)\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "        \n",
    "# Run the server in a separate thread to avoid blocking the notebook\n",
    "from threading import Thread\n",
    "def run_jupyter_server():\n",
    "    jupyter_app.run(host='127.0.0.1', port=5001, debug=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Start the server in a thread\n",
    "    server_thread = Thread(target=run_jupyter_server)\n",
    "    server_thread.daemon = True  # Stops when notebook stops\n",
    "    server_thread.start()\n",
    "    print(\"Jupyter question generator server running on port 5001...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95b5dfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramana\n",
      "18\n",
      "India\n",
      "Student\n",
      "ComputerScience\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(human.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
